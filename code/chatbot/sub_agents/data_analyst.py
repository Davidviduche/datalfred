import uuid
import boto3
import awswrangler as wr
from strands import tool, Agent
from strands.types.tools import ToolContext
from strands.session.file_session_manager import FileSessionManager
from strands.handlers.callback_handler import PrintingCallbackHandler

@tool
def list_databases() -> dict:
    """
    Returns a dict of databases available in the AWS Glue Data Catalog,
    including their descriptions if available.

    Returns:
        dict: Dictionary containing as keys the database names and as values each database descriptions.
    """
    glue_client = boto3.client("glue")
    response = glue_client.get_databases()
    return {
        db["Name"]: db.get("Description", "No description found.")
        for db in response["DatabaseList"]
    }

@tool
def list_tables(database_name: str) -> list:
    """
    Returns the list of tables for a given database in the Glue Data Catalog,
    including their descriptions if available.

    Args:
        database_name (str): name of the database from which we want the tables

    Returns:
        list: List of tables, each being a dictionary which has the following keys: "Name" with the table name, "Description" with the table description and "Schema" with the table schema, which is a list of Dictionaries with the following keys: "Name" with the column name, "Type" with the column type and "Description" with the column description.
    """
    glue_client = boto3.client("glue")
    tables_dict_list = glue_client.get_tables(DatabaseName=database_name)["TableList"]
    tables_info = []
    for table_dict in tables_dict_list:
        tables_info.append({
            "Name": table_dict["Name"],
            "Description": table_dict.get("Description", "No description found"),
            "Schema": [
                {
                    "Name": col["Name"],
                    "Type": col["Type"],
                    "Description": col.get("Comment", "No description found.")
                }
                for col in table_dict["StorageDescriptor"]["Columns"] + table_dict.get("PartitionKeys", [])
            ]
        })
    return tables_info


@tool(context=True)
def query_athena(sql_query: str, database_name: str, tool_context: ToolContext) -> list:
    """
    Executes an Athena SQL query. The input should be a SQL query string
    (usually generated by an LLM from a natural language question) and the database name against which the query should run.
    Results are returned as a list of dictionaries (records).

    Args:
        sql_query (str): SQL query to run in Athena
        database_name (str): name of the database against which the sql query should run

    Returns:
        dict: result of the query in the form of a list of dictionaries (records).
    """
    environment_name = f"{tool_context.agent.state.get('project_name')}_" + \
        f"{tool_context.agent.state.get('domain_name')}_" + \
        f"{tool_context.agent.state.get('stage_name')}"
    try:
        df = wr.athena.read_sql_query(
            sql=sql_query,
            workgroup=environment_name,
            database=database_name,
            ctas_approach=False
        )
        return df.to_dict(orient="records")
    except Exception as error:
        return "TOOL_ERROR: The SQL request execution failed with following error: " + str(error)

DATA_ANALYST_SYSTEM_PROMPT = """
You are an assistant that finds the relevant database to anwser the user question using exclusively the tools at your disposal.
You can then query data in Athena and analyse the results to answer user question.
Always get the table info before building the Athena SQL query
IF A TOOL FAILS, GIVE THE FULL ERROR, UNLESS IT IS A SQL SYNTAX ERROR DO NOT RETRY
"""

@tool(context=True)
def data_analyst_agent(user_prompt: str, tool_context: ToolContext):
    """
    This tool provides a data analyst which is able to query data in the datalake (Glue Data Catalog and Athena to query data) and analyze results

    Args:
        user_prompt (str): question to ask to the data analyst

    Returns:
        str
    """
    if "DATA_ANALYST_AGENT" not in globals():
        global DATA_ANALYST_AGENT
        DATA_ANALYST_AGENT = Agent(
            model=tool_context.agent.state.get("inference_profile_arn"),
            system_prompt=DATA_ANALYST_SYSTEM_PROMPT,
            callback_handler=PrintingCallbackHandler()
            if tool_context.agent.state.get("print_sub_agent_debug") else None,
            session_manager=FileSessionManager(
                session_id=f"strands-data-analyst-session-{str(uuid.uuid1())}"),
            tools=[list_databases, list_tables, query_athena])
        DATA_ANALYST_AGENT.state.set("project_name", tool_context.agent.state.get("project_name"))
        DATA_ANALYST_AGENT.state.set("domain_name", tool_context.agent.state.get("domain_name"))
        DATA_ANALYST_AGENT.state.set("stage_name", tool_context.agent.state.get("stage_name"))
    agent_response = DATA_ANALYST_AGENT(user_prompt)
    total_input_tokens = tool_context.agent.state.get("total_input_tokens") if tool_context.agent.state.get("total_input_tokens") else 0
    total_output_tokens = tool_context.agent.state.get("total_output_tokens") if tool_context.agent.state.get("total_output_tokens") else 0
    tool_context.agent.state.set(
        "total_output_tokens",
        total_output_tokens + agent_response.metrics.accumulated_usage["outputTokens"])
    tool_context.agent.state.set(
        "total_input_tokens",
        total_input_tokens + agent_response.metrics.accumulated_usage["inputTokens"])
    return agent_response
